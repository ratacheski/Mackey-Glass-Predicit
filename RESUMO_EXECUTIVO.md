# ğŸ“Š Resumo Executivo - Trabalho 2 RNP

## ğŸ“š NavegaÃ§Ã£o

- **[ğŸ“– README.md](README.md)** - DocumentaÃ§Ã£o completa
- **[ğŸš€ COMO_USAR.md](COMO_USAR.md)** - Guia rÃ¡pido de uso
- **[ğŸ“Š RESUMO_EXECUTIVO.md](RESUMO_EXECUTIVO.md)** - VisÃ£o geral do projeto (vocÃª estÃ¡ aqui)
- **[ğŸ“ˆ RESULTADOS_FINAIS.md](RESULTADOS_FINAIS.md)** - Resultados dos experimentos

---

## ğŸ¯ Objetivo
Implementar e comparar trÃªs arquiteturas de redes neurais (MLP, LSTM, GRU) para prediÃ§Ã£o da sÃ©rie temporal Mackey-Glass, com mÃºltiplas configuraÃ§Ãµes e variaÃ§Ãµes para anÃ¡lise abrangente.

## âœ… Status do Projeto
**IMPLEMENTAÃ‡ÃƒO COMPLETA** âœ…

## ğŸ—ï¸ Arquitetura Implementada

### Modelos DisponÃ­veis (15 configuraÃ§Ãµes)

> **ğŸ“– Para detalhes completos, consulte [README.md](README.md#modelos-disponÃ­veis)**

#### MLP (Multi-Layer Perceptron)
- **mlp_small**: 2 camadas [64, 32], ~3K parÃ¢metros
- **mlp_medium**: 3 camadas [128, 64, 32], ~14K parÃ¢metros  
- **mlp_large**: 4 camadas [256, 128, 64, 32], ~59K parÃ¢metros

#### LSTM (Long Short-Term Memory)
- **lstm_small**: 1 camada, 32 unidades, ~8K parÃ¢metros
- **lstm_medium**: 2 camadas, 64 unidades, ~50K parÃ¢metros
- **lstm_large**: 3 camadas, 128 unidades, ~200K parÃ¢metros
- **lstm_bidirectional**: 2 camadas bidirecionais, 64 unidades
- **lstm_attention**: 2 camadas com atenÃ§Ã£o, 64 unidades

#### GRU (Gated Recurrent Unit)
- **gru_small**: 1 camada, 32 unidades, ~6K parÃ¢metros
- **gru_medium**: 2 camadas, 64 unidades, ~37K parÃ¢metros
- **gru_large**: 3 camadas, 128 unidades, ~150K parÃ¢metros
- **gru_bidirectional**: 2 camadas bidirecionais, 64 unidades
- **gru_attention**: 2 camadas com atenÃ§Ã£o, 64 unidades

## ğŸš€ Como Executar

> **ğŸš€ Para instruÃ§Ãµes detalhadas, consulte [COMO_USAR.md](COMO_USAR.md)**

### Experimento PadrÃ£o (Modelos Principais)
```bash
cd mackey_glass_prediction/experiments
python run_experiment.py
```
**Executa**: `mlp_large`, `lstm_large`, `gru_large`

### Experimento Completo (Todos os Modelos)
```bash
python run_experiment.py --models all
```
**Executa**: Todos os 15 modelos (pode demorar vÃ¡rias horas)

### Teste RÃ¡pido
```bash
python run_experiment.py --models mlp_small lstm_small gru_small --no-save
```

## ğŸ“ Estrutura do Projeto

```
Trabalho2RNP/
â”œâ”€â”€ RESULTADOS_FINAIS.md              # RelatÃ³rio pÃ³s-experimentos
â”œâ”€â”€ COMO_USAR.md                      # Guia detalhado de uso
â”œâ”€â”€ RESUMO_EXECUTIVO.md               # Este arquivo
â””â”€â”€ mackey_glass_prediction/          # CÃ³digo fonte
    â”œâ”€â”€ config/config.py              # 15 configuraÃ§Ãµes de modelos
    â”œâ”€â”€ data/mackey_glass_generator.py # GeraÃ§Ã£o da sÃ©rie temporal
    â”œâ”€â”€ models/                       # 3 tipos de modelos
    â”‚   â”œâ”€â”€ mlp_model.py             # MLP com variaÃ§Ãµes
    â”‚   â”œâ”€â”€ lstm_model.py            # LSTM + bidirectional + attention
    â”‚   â””â”€â”€ gru_model.py             # GRU + bidirectional + attention
    â”œâ”€â”€ utils/                        # MÃ³dulos auxiliares
    â”‚   â”œâ”€â”€ training.py              # Treinamento e avaliaÃ§Ã£o
    â”‚   â””â”€â”€ visualization/           # 7 mÃ³dulos de visualizaÃ§Ã£o
    â”œâ”€â”€ experiments/                  # Scripts de execuÃ§Ã£o
    â”‚   â””â”€â”€ run_experiment.py        # Script principal
    â”œâ”€â”€ generate_interactive_report.py # RelatÃ³rio HTML demonstrativo
    â””â”€â”€ requirements.txt             # 22 dependÃªncias
```

## âš™ï¸ ConfiguraÃ§Ãµes do Experimento

### SÃ©rie Mackey-Glass
- **Pontos**: 10.000
- **ParÃ¢metros**: Ï„=20, Î²=0.4, Î³=0.2, n=18, xâ‚€=0.8
- **Janela de entrada**: 20 pontos
- **PrediÃ§Ã£o**: 1 passo Ã  frente

### Dataset
- **DivisÃ£o**: 90% treino, 10% validaÃ§Ã£o
- **Batch size**: 8192
- **NormalizaÃ§Ã£o**: Min-Max Scaling

### Treinamento
- **Ã‰pocas mÃ¡ximas**: 150
- **Early stopping**: 15 Ã©pocas de paciÃªncia
- **Otimizador**: Adam (lr=1e-3)
- **Scheduler**: ReduceLROnPlateau
- **RegularizaÃ§Ã£o**: L2 (1e-5) + Dropout

## ğŸ“Š SaÃ­das Geradas

### Estrutura de Resultados
```
experiments/results/final_report_[timestamp]/
â”œâ”€â”€ 01_visao_geral_[timestamp].png           # ComparaÃ§Ã£o geral
â”œâ”€â”€ [modelo]/                               # Para cada modelo:
â”‚   â”œâ”€â”€ training_curves.png                 # Curvas de loss
â”‚   â”œâ”€â”€ predictions.png                     # PrediÃ§Ãµes vs reais
â”‚   â”œâ”€â”€ [modelo]_qq_plot_[timestamp].png    # AnÃ¡lise Q-Q
â”‚   â”œâ”€â”€ [modelo]_cdf_[timestamp].png        # AnÃ¡lise CDF
â”‚   â”œâ”€â”€ best_model.pth                      # Melhor modelo
â”‚   â””â”€â”€ final_model.pth                     # Modelo final
â”œâ”€â”€ 99_tabela_metricas_[timestamp].png      # Tabela formatada
â”œâ”€â”€ 99_comparacao_metricas_[timestamp].png  # ComparaÃ§Ã£o visual
â”œâ”€â”€ metrics_table.csv                       # Dados em CSV
â””â”€â”€ relatorio.html                          # RelatÃ³rio interativo
```

### MÃ©tricas Avaliadas

#### MÃ©tricas BÃ¡sicas
- **MSE**: Mean Squared Error
- **RMSE**: Root Mean Squared Error
- **MAE**: Mean Absolute Error
- **MAPE**: Mean Absolute Percentage Error
- **RÂ²**: Coeficiente de determinaÃ§Ã£o

#### MÃ©tricas Normalizadas
- **EQMN1**: Erro QuadrÃ¡tico MÃ©dio Normalizado pela VariÃ¢ncia
  - **FÃ³rmula**: EQMN1 = MSE / Var(y_true)
  - **InterpretaÃ§Ã£o**: < 0.1 excelente, < 0.5 bom
- **EQMN2**: Erro QuadrÃ¡tico MÃ©dio Normalizado pelo Modelo Naive
  - **FÃ³rmula**: EQMN2 = MSE / MSE_naive (modelo de persistÃªncia)
  - **InterpretaÃ§Ã£o**: < 1.0 melhor que naive, < 0.5 excelente

## âœ¨ Funcionalidades Implementadas

### ğŸ§  Modelos AvanÃ§ados
- âœ… MLP com mÃºltiplas camadas e dropout adaptativo
- âœ… LSTM com opÃ§Ãµes bidirecionais e mecanismo de atenÃ§Ã£o
- âœ… GRU com opÃ§Ãµes bidirecionais e mecanismo de atenÃ§Ã£o
- âœ… Arquiteturas escalÃ¡veis (small, medium, large)

### ğŸ”¬ Treinamento Robusto
- âœ… Early stopping inteligente
- âœ… Learning rate scheduling
- âœ… RegularizaÃ§Ã£o L2 + Dropout
- âœ… Checkpoint automÃ¡tico (melhor modelo)
- âœ… Seeds fixas para reprodutibilidade

### ğŸ“Š VisualizaÃ§Ãµes Completas
- âœ… Curvas de treinamento e validaÃ§Ã£o
- âœ… ComparaÃ§Ã£o de prediÃ§Ãµes vs valores reais
- âœ… AnÃ¡lise estatÃ­stica de resÃ­duos (Q-Q plots, CDF)
- âœ… Tabelas de mÃ©tricas formatadas
- âœ… GrÃ¡ficos comparativos entre modelos
- âœ… RelatÃ³rios HTML interativos

### ğŸ› ï¸ Infraestrutura
- âœ… ConfiguraÃ§Ãµes centralizadas
- âœ… Modularidade e extensibilidade
- âœ… Interface de linha de comando flexÃ­vel
- âœ… DetecÃ§Ã£o automÃ¡tica GPU/CPU
- âœ… Logging detalhado
- âœ… Tratamento de erros

### ğŸ“ˆ AnÃ¡lises EstatÃ­sticas
- âœ… DistribuiÃ§Ã£o de resÃ­duos
- âœ… Testes de normalidade
- âœ… AnÃ¡lise de autocorrelaÃ§Ã£o
- âœ… MÃ©tricas mÃºltiplas (RÂ², MAPE, EQMN1, EQMN2, etc.)
- âœ… ComparaÃ§Ã£o estatÃ­stica entre modelos

## ğŸ›ï¸ OpÃ§Ãµes de ExecuÃ§Ã£o

### BÃ¡sicas
```bash
python run_experiment.py                    # Modelos principais
python run_experiment.py --models all       # Todos os modelos
python run_experiment.py --no-save          # Sem salvar resultados
```

### EspecÃ­ficas
```bash
python run_experiment.py --models mlp_medium lstm_attention
python run_experiment.py --output-dir meu_experimento
python run_experiment.py --models gru_large --no-save
```

### AnÃ¡lise
```bash
python generate_interactive_report.py       # RelatÃ³rio demonstrativo
```

## ğŸ† CaracterÃ­sticas TÃ©cnicas

### Escalabilidade
- 3 tipos de modelos Ã— 5 configuraÃ§Ãµes = 15 modelos
- ParÃ¢metros de 3K (mlp_small) atÃ© 200K (lstm_large)
- Suporte para experimentaÃ§Ã£o em larga escala

### Robustez
- Tratamento automÃ¡tico de GPU/CPU
- Early stopping para evitar overfitting
- ValidaÃ§Ã£o cruzada temporal
- NormalizaÃ§Ã£o e desnormalizaÃ§Ã£o automÃ¡tica

### Reprodutibilidade
- Seeds fixas para todos os experimentos
- ConfiguraÃ§Ãµes versionadas
- Checkpoints automÃ¡ticos
- Logs detalhados de execuÃ§Ã£o

### Usabilidade
- Interface simples e intuitiva
- DocumentaÃ§Ã£o abrangente
- RelatÃ³rios visuais automÃ¡ticos
- Debugging facilitado com modo --no-save

## ğŸ“‹ PrÃ³ximos Passos

1. **Executar experimentos**: `python run_experiment.py`
2. **Analisar resultados**: Verificar pasta `results/final_report_*/`
3. **Comparar modelos**: Consultar `metrics_table.csv`
4. **Gerar relatÃ³rio**: `python generate_interactive_report.py`
5. **Atualizar RESULTADOS_FINAIS.md**: Com mÃ©tricas reais obtidas

## ğŸ“š Links Ãšteis

- **[ğŸš€ COMO_USAR.md](COMO_USAR.md)** - Guia prÃ¡tico de execuÃ§Ã£o
- **[ğŸ“– README.md](README.md)** - DocumentaÃ§Ã£o tÃ©cnica completa
- **[ğŸ“ˆ RESULTADOS_FINAIS.md](RESULTADOS_FINAIS.md)** - AnÃ¡lise dos resultados experimentais

---
**Desenvolvido por**: Rafael Ratacheski de Sousa Raulino  
**Mestrando em Engenharia ElÃ©trica e de ComputaÃ§Ã£o - UFG**  
**Disciplina**: Redes Neurais Profundas - 2025/1  
**Data**: 29 de Maio de 2025  
**Status**: âœ… IMPLEMENTAÃ‡ÃƒO COMPLETA
# ğŸ§  Trabalho 2 - Redes Neurais Profundas
**PrediÃ§Ã£o de SÃ©ries Temporais Mackey-Glass com Arquiteturas MLP, LSTM e GRU**

---

## ğŸ“‹ NavegaÃ§Ã£o

- [ğŸ“– README](README.md) â† **VocÃª estÃ¡ aqui**
- [ğŸš€ Como Usar](COMO_USAR.md)
- [ğŸ“Š Resumo Executivo](RESUMO_EXECUTIVO.md)
- [ğŸ“ˆ Resultados Finais](RESULTADOS_FINAIS.md)

## ğŸŒ Demo Online

[![GitHub Pages](https://img.shields.io/badge/GitHub%20Pages-Live%20Demo-brightgreen?style=for-the-badge&logo=github)](https://ratacheski.github.io/Mackey-Glass-Predicit/)

ğŸ”´ **Acesse o relatÃ³rio interativo online**: [Clique aqui para ver o demo](https://ratacheski.github.io/Mackey-Glass-Predicit/relatorio.html)

## ğŸ¯ Objetivo

Este projeto implementa e compara **trÃªs arquiteturas de redes neurais** (MLP, LSTM, GRU) para prediÃ§Ã£o da sÃ©rie temporal Mackey-Glass, explorando diferentes configuraÃ§Ãµes e tÃ©cnicas avanÃ§adas para anÃ¡lise abrangente de desempenho.

# PrediÃ§Ã£o de SÃ©ries Temporais Mackey-Glass com Redes Neurais

Este projeto implementa trÃªs tipos de redes neurais (MLP, LSTM, GRU) para prediÃ§Ã£o de sÃ©ries temporais de Mackey-Glass usando PyTorch, com mÃºltiplas configuraÃ§Ãµes e variaÃ§Ãµes para cada modelo.

## ğŸ“š NavegaÃ§Ã£o

- **[ğŸ“– README.md](README.md)** - DocumentaÃ§Ã£o completa (vocÃª estÃ¡ aqui)
- **[ğŸš€ COMO_USAR.md](COMO_USAR.md)** - Guia rÃ¡pido de uso
- **[ğŸ“Š RESUMO_EXECUTIVO.md](RESUMO_EXECUTIVO.md)** - VisÃ£o geral do projeto
- **[ğŸ“ˆ RESULTADOS_FINAIS.md](RESULTADOS_FINAIS.md)** - Resultados dos experimentos

---

## Estrutura do Projeto

```
mackey_glass_prediction/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py                    # ConfiguraÃ§Ãµes centralizadas dos experimentos
â”œâ”€â”€ data/
â”‚   â””â”€â”€ mackey_glass_generator.py    # GeraÃ§Ã£o da sÃ©rie e datasets
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ run_experiment.py            # Script principal para executar experimentos
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py                  # ImportaÃ§Ã£o dos modelos
â”‚   â”œâ”€â”€ mlp_model.py                 # Modelo MLP com variaÃ§Ãµes
â”‚   â”œâ”€â”€ lstm_model.py                # Modelo LSTM com variaÃ§Ãµes
â”‚   â””â”€â”€ gru_model.py                 # Modelo GRU com variaÃ§Ãµes
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ training.py                  # FunÃ§Ãµes de treinamento e avaliaÃ§Ã£o
â”‚   â””â”€â”€ visualization/               # MÃ³dulo completo de visualizaÃ§Ã£o
â”‚       â”œâ”€â”€ __init__.py              # FunÃ§Ãµes bÃ¡sicas de plotting
â”‚       â”œâ”€â”€ basic_plots.py           # GrÃ¡ficos bÃ¡sicos
â”‚       â”œâ”€â”€ comparison_plots.py      # GrÃ¡ficos de comparaÃ§Ã£o
â”‚       â”œâ”€â”€ distribution_analysis.py # AnÃ¡lise de distribuiÃ§Ã£o
â”‚       â”œâ”€â”€ interactive_html.py      # RelatÃ³rios HTML interativos
â”‚       â”œâ”€â”€ reports.py               # GeraÃ§Ã£o de relatÃ³rios
â”‚       â”œâ”€â”€ statistical_tests.py    # Testes estatÃ­sticos
â”‚       â””â”€â”€ utils.py                 # UtilitÃ¡rios de visualizaÃ§Ã£o
â”œâ”€â”€ generate_interactive_report.py   # Script para gerar relatÃ³rios interativos
â”œâ”€â”€ requirements.txt                 # DependÃªncias do projeto
â””â”€â”€ README.md                        # Este arquivo
```

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <url-do-repositorio>
cd mackey_glass_prediction
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## Uso

> **ğŸ’¡ Para uso rÃ¡pido, consulte [COMO_USAR.md](COMO_USAR.md)**

### Executar experimentos principais (trÃªs modelos grandes)

```bash
cd experiments
python run_experiment.py
```

Por padrÃ£o, executa os modelos principais: `mlp_large`, `lstm_large`, `gru_large`

### Executar modelos especÃ­ficos

```bash
# Executar apenas um modelo
python run_experiment.py --models mlp_medium

# Executar mÃºltiplos modelos especÃ­ficos
python run_experiment.py --models lstm_medium gru_medium mlp_small

# Executar todos os modelos disponÃ­veis
python run_experiment.py --models all
```

### OpÃ§Ãµes de linha de comando

- `--models`: Especifica quais modelos executar
  - `main`: Executa os trÃªs modelos principais (padrÃ£o): `mlp_large`, `lstm_large`, `gru_large`
  - `all`: Executa todas as configuraÃ§Ãµes disponÃ­veis (15 modelos)
  - Nomes especÃ­ficos: qualquer combinaÃ§Ã£o dos modelos disponÃ­veis
- `--no-save`: NÃ£o salva os resultados (Ãºtil para testes rÃ¡pidos)
- `--output-dir`: Prefixo personalizado para a pasta de saÃ­da

### Exemplo de uso programÃ¡tico

```python
from experiments.run_experiment import run_single_experiment

# Executar um Ãºnico experimento
results = run_single_experiment('lstm_medium')

# Acessar mÃ©tricas
print(f"RMSE: {results['metrics']['RMSE']:.6f}")
print(f"RÂ²: {results['metrics']['RÂ²']:.6f}")
print(f"EQMN1: {results['metrics']['EQMN1']:.6f}")
print(f"EQMN2: {results['metrics']['EQMN2']:.6f}")
```

## Modelos DisponÃ­veis

### MLP (Multi-Layer Perceptron)
- **mlp_small**: 2 camadas ocultas [64, 32], ~3K parÃ¢metros
- **mlp_medium**: 3 camadas ocultas [128, 64, 32], ~14K parÃ¢metros  
- **mlp_large**: 4 camadas ocultas [256, 128, 64, 32], ~59K parÃ¢metros

### LSTM (Long Short-Term Memory)
- **lstm_small**: 1 camada, 32 unidades, ~8K parÃ¢metros
- **lstm_medium**: 2 camadas, 64 unidades, ~50K parÃ¢metros
- **lstm_large**: 3 camadas, 128 unidades, ~200K parÃ¢metros
- **lstm_bidirectional**: 2 camadas bidirecionais, 64 unidades
- **lstm_attention**: 2 camadas com mecanismo de atenÃ§Ã£o, 64 unidades

### GRU (Gated Recurrent Unit)
- **gru_small**: 1 camada, 32 unidades, ~6K parÃ¢metros
- **gru_medium**: 2 camadas, 64 unidades, ~37K parÃ¢metros
- **gru_large**: 3 camadas, 128 unidades, ~150K parÃ¢metros
- **gru_bidirectional**: 2 camadas bidirecionais, 64 unidades
- **gru_attention**: 2 camadas com mecanismo de atenÃ§Ã£o, 64 unidades

## ConfiguraÃ§Ãµes

As configuraÃ§Ãµes estÃ£o centralizadas em `config/config.py`:

### ParÃ¢metros da SÃ©rie Mackey-Glass
```python
MACKEY_GLASS_CONFIG = {
    'n_points': 10000,  # NÃºmero de pontos
    'tau': 20,          # ParÃ¢metro de delay
    'gamma': 0.2,       # ParÃ¢metro gamma
    'beta': 0.4,        # ParÃ¢metro beta
    'n': 18,            # ParÃ¢metro n
    'x0': 0.8           # Valor inicial
}
```

### ConfiguraÃ§Ãµes do Dataset
```python
DATASET_CONFIG = {
    'window_size': 20,        # Tamanho da janela de entrada
    'prediction_steps': 1,    # Passos Ã  frente para predizer
    'train_ratio': 0.9,       # 90% para treino, 10% para validaÃ§Ã£o
    'batch_size': 8192,       # Tamanho do batch
    'shuffle_train': True     # Embaralhar dados de treino
}
```

### ConfiguraÃ§Ãµes de Treinamento
```python
TRAINING_CONFIG = {
    'epochs': 150,
    'learning_rate': 1e-3,
    'weight_decay': 1e-5,
    'patience': 15,           # Early stopping
    'min_delta': 1e-6,        # MÃ­nima melhoria
    'use_scheduler': True,    # Scheduler de learning rate
    'save_best_model': True,
    'save_final_model': True
}
```

## Resultados e VisualizaÃ§Ãµes

ApÃ³s executar os experimentos, sÃ£o gerados:

### 1. Estrutura de SaÃ­da
```
experiments/results/
â”œâ”€â”€ final_report_[timestamp]/
â”‚   â”œâ”€â”€ 01_visao_geral_[timestamp].png       # VisÃ£o geral comparativa
â”‚   â”œâ”€â”€ [modelo]/                            # Pasta para cada modelo
â”‚   â”‚   â”œâ”€â”€ training_curves.png              # Curvas de treinamento
â”‚   â”‚   â”œâ”€â”€ predictions.png                  # GrÃ¡fico de prediÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ best_model.pth                   # Melhor modelo salvo
â”‚   â”‚   â””â”€â”€ final_model.pth                  # Modelo final
â”‚   â”œâ”€â”€ 99_tabela_metricas_[timestamp].png   # Tabela de mÃ©tricas
â”‚   â”œâ”€â”€ 99_comparacao_metricas_[timestamp].png # ComparaÃ§Ã£o visual
â”‚   â”œâ”€â”€ metrics_table.csv                    # MÃ©tricas em CSV
â”‚   â””â”€â”€ relatorio.html                       # RelatÃ³rio HTML interativo
```

### 2. RelatÃ³rio HTML Interativo
```bash
# Gerar relatÃ³rio interativo demonstrativo
python generate_interactive_report.py
```

### 3. MÃ©tricas Avaliadas

#### MÃ©tricas BÃ¡sicas
- **MSE**: Mean Squared Error
- **RMSE**: Root Mean Squared Error
- **MAE**: Mean Absolute Error
- **MAPE**: Mean Absolute Percentage Error
- **RÂ²**: Coeficiente de determinaÃ§Ã£o

#### MÃ©tricas Normalizadas
- **EQMN1**: Erro QuadrÃ¡tico MÃ©dio Normalizado pela VariÃ¢ncia
  - **FÃ³rmula**: EQMN1 = MSE / Var(y_true)
  - **InterpretaÃ§Ã£o**: Valores menores indicam melhor performance. < 0.1 Ã© excelente, < 0.5 Ã© bom
- **EQMN2**: Erro QuadrÃ¡tico MÃ©dio Normalizado pelo Modelo Naive
  - **FÃ³rmula**: EQMN2 = MSE / MSE_naive (modelo de persistÃªncia)
  - **InterpretaÃ§Ã£o**: < 1.0 indica que o modelo Ã© melhor que naive, < 0.5 Ã© excelente

### 4. VisualizaÃ§Ãµes Geradas
- GrÃ¡ficos de loss durante treinamento
- ComparaÃ§Ã£o entre prediÃ§Ãµes e valores reais
- AnÃ¡lise de distribuiÃ§Ã£o de resÃ­duos
- GrÃ¡ficos Q-Q e CDF dos resÃ­duos
- ComparaÃ§Ã£o visual entre modelos
- Tabelas de mÃ©tricas formatadas

## SÃ©rie Temporal Mackey-Glass

A sÃ©rie Ã© gerada pela equaÃ§Ã£o diferencial com atraso:
```
dx/dt = Î²x(t-Ï„)/(1 + x(t-Ï„)^n) - Î³x(t)
```

ParÃ¢metros padrÃ£o:
- Ï„ = 20 (delay)
- Î² = 0.4
- Î³ = 0.2
- n = 18
- xâ‚€ = 0.8 (condiÃ§Ã£o inicial)

## Desenvolvimento

### Adicionando novos modelos

1. Crie um novo arquivo em `models/` seguindo o padrÃ£o dos existentes
2. Implemente a classe herdando de `torch.nn.Module`
3. Adicione mÃ©todos obrigatÃ³rios: `forward()`, `get_model_info()`, `print_model_summary()`
4. Atualize `models/__init__.py`
5. Adicione configuraÃ§Ã£o em `config/config.py` no dicionÃ¡rio `MODEL_CONFIGS`

### Exemplo de novo modelo
```python
# models/transformer_model.py
import torch
import torch.nn as nn

class TransformerModel(nn.Module):
    def __init__(self, input_size, d_model, nhead, num_layers, output_size):
        super().__init__()
        # ImplementaÃ§Ã£o do modelo
        
    def forward(self, x):
        # Forward pass
        
    def get_model_info(self):
        """Retornar informaÃ§Ãµes do modelo para relatÃ³rios"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'architecture': 'Transformer',
            # Adicione outras informaÃ§Ãµes especÃ­ficas do modelo
        }
        
    def print_model_summary(self):
        """Imprimir resumo do modelo"""
        info = self.get_model_info()
        print(f"Modelo: {info['architecture']}")
        print(f"ParÃ¢metros totais: {info['total_parameters']:,}")
        print(f"ParÃ¢metros treinÃ¡veis: {info['trainable_parameters']:,}")
```

### Personalizando ConfiguraÃ§Ãµes

Para criar experimentos personalizados, edite `config/config.py`:

```python
# Adicionar nova configuraÃ§Ã£o de modelo
MODEL_CONFIGS['meu_modelo_custom'] = {
    'model_type': 'lstm',
    'input_size': 1,
    'hidden_size': 96,
    'num_layers': 4,
    'output_size': 1,
    'dropout_rate': 0.25,
    'bidirectional': True,
    'use_attention': True
}
```

## DependÃªncias Principais

- **PyTorch**: Framework de deep learning
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **Matplotlib**: VisualizaÃ§Ã£o bÃ¡sica
- **Seaborn**: VisualizaÃ§Ã£o estatÃ­stica
- **Pandas**: ManipulaÃ§Ã£o de dados
- **Scikit-learn**: MÃ©tricas e utilities
- **SciPy**: ComputaÃ§Ã£o cientÃ­fica
- **TQDM**: Barras de progresso

## Links Ãšteis

- **[ğŸš€ Guia de Uso RÃ¡pido](COMO_USAR.md)** - Como executar os experimentos
- **[ğŸ“Š Resumo Executivo](RESUMO_EXECUTIVO.md)** - VisÃ£o geral do projeto
- **[ğŸ“ˆ Resultados Finais](RESULTADOS_FINAIS.md)** - AnÃ¡lise dos resultados experimentais

## ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

## Autor

**Rafael Ratacheski de Sousa Raulino**  
Mestrando em Engenharia ElÃ©trica e de ComputaÃ§Ã£o - UFG  
Disciplina: Redes Neurais Profundas - 2025/1 
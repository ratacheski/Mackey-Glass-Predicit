# ğŸ“ˆ Resultados Finais - PrediÃ§Ã£o de SÃ©rie Temporal Mackey-Glass

## ğŸ“š NavegaÃ§Ã£o

- **[ğŸ“– README.md](README.md)** - DocumentaÃ§Ã£o completa
- **[ğŸš€ COMO_USAR.md](COMO_USAR.md)** - Guia rÃ¡pido de uso
- **[ğŸ“Š RESUMO_EXECUTIVO.md](RESUMO_EXECUTIVO.md)** - VisÃ£o geral do projeto
- **[ğŸ“ˆ RESULTADOS_FINAIS.md](RESULTADOS_FINAIS.md)** - Resultados dos experimentos (vocÃª estÃ¡ aqui)

---

## ğŸ“Š Resumo Executivo dos Experimentos

Este documento apresenta os **resultados finais** dos experimentos de prediÃ§Ã£o da sÃ©rie temporal Mackey-Glass utilizando diferentes arquiteturas de redes neurais. **7 modelos** foram avaliados com configuraÃ§Ãµes otimizadas.

**Data do Experimento**: 01 de Junho de 2025  
**NÃºmero de Modelos Avaliados**: 7  
**Dataset**: 998 pontos de validaÃ§Ã£o  

## ğŸ† Ranking Geral dos Modelos

### ğŸ¥‡ 1Âº Lugar: lstm_bidirectional
- **Score Total**: 5.5639
- **RÂ²**: 0.990789 (**Excepcional**)
- **RMSE**: 0.036060 (**Melhor**)
- **MAE**: 0.026156
- **MAPE**: 4.98% (**Muito baixo**)
- **EQMN1**: 0.009211 (**Excelente**)
- **EQMN2**: 0.159208 (**Muito superior ao naive**)

### ğŸ¥ˆ 2Âº Lugar: gru_bidirectional
- **Score Total**: 5.0892
- **RÂ²**: 0.984880
- **RMSE**: 0.046200
- **MAE**: 0.035896
- **MAPE**: 7.06%
- **EQMN1**: 0.01512 (**Excelente**)
- **EQMN2**: 0.26133 (**Superior ao naive**)

### ğŸ¥‰ 3Âº Lugar: gru_large
- **Score Total**: 5.0521
- **RÂ²**: 0.984210
- **RMSE**: 0.047213
- **MAE**: 0.036454
- **MAPE**: 8.66%
- **EQMN1**: 0.01579 (**Excelente**)
- **EQMN2**: 0.272916 (**Superior ao naive**)

### 4Âº Lugar: lstm_large
- **Score Total**: 5.0431
- **RÂ²**: 0.983583
- **RMSE**: 0.048141
- **MAE**: 0.035985
- **MAPE**: 6.56%
- **EQMN1**: 0.016417 (**Excelente**)
- **EQMN2**: 0.283757 (**Superior ao naive**)

### 5Âº Lugar: gru_attention
- **Score Total**: 4.9242
- **RÂ²**: 0.982544
- **RMSE**: 0.049641
- **MAE**: 0.039312
- **MAPE**: 8.25%
- **EQMN1**: 0.017456 (**Excelente**)
- **EQMN2**: 0.301715 (**Superior ao naive**)

### 6Âº Lugar: lstm_attention
- **Score Total**: 4.8223
- **RÂ²**: 0.980030
- **RMSE**: 0.053096
- **MAE**: 0.040231
- **MAPE**: 7.29%
- **EQMN1**: 0.01997 (**Bom**)
- **EQMN2**: 0.345174 (**Superior ao naive**)

### 7Âº Lugar: mlp_large
- **Score Total**: 2.7983
- **RÂ²**: 0.932776
- **RMSE**: 0.097416
- **MAE**: 0.078291
- **MAPE**: 26.59% (**Alto**)
- **EQMN1**: 0.067224 (**Bom**)
- **EQMN2**: 1.161922 (**Inferior ao naive**)

## ğŸ“ˆ MÃ©tricas Detalhadas

### Tabela Completa de Resultados

| Modelo | MSE | RMSE | MAE | MAPE (%) | RÂ² | EQMN1 | EQMN2 | ClassificaÃ§Ã£o |
|--------|-----|------|-----|----------|-------|-------|-------|---------------|
| **lstm_bidirectional** | 0.001300 | 0.036060 | 0.026156 | 4.98 | **0.990789** | **0.009211** | **0.159208** | ğŸ¥‡ EXCEPCIONAL |
| **gru_bidirectional** | 0.002134 | 0.046200 | 0.035896 | 7.06 | 0.984880 | 0.01512 | 0.26133 | ğŸ¥ˆ EXCELENTE |
| **gru_large** | 0.002229 | 0.047213 | 0.036454 | 8.66 | 0.984210 | 0.01579 | 0.272916 | ğŸ¥‰ EXCELENTE |
| **lstm_large** | 0.002318 | 0.048141 | 0.035985 | 6.56 | 0.983583 | 0.016417 | 0.283757 | 4Âº EXCELENTE |
| **gru_attention** | 0.002464 | 0.049641 | 0.039312 | 8.25 | 0.982544 | 0.017456 | 0.301715 | 5Âº EXCELENTE |
| **lstm_attention** | 0.002819 | 0.053096 | 0.040231 | 7.29 | 0.980030 | 0.01997 | 0.345174 | 6Âº EXCELENTE |
| **mlp_large** | 0.009490 | 0.097416 | 0.078291 | 26.59 | 0.932776 | 0.067224 | 1.161922 | 7Âº BOM |

## ğŸ”¬ AnÃ¡lise TÃ©cnica dos Resultados

### ğŸ“Š Performance por Arquitetura

#### LSTM (Long Short-Term Memory)
- **Melhor Modelo**: lstm_bidirectional (1Âº lugar)
- **CaracterÃ­sticas**: Arquiteturas bidirecionais superaram unidirecionais
- **Destaque**: lstm_bidirectional obteve a **melhor performance geral**
- **LimitaÃ§Ã£o**: lstm_attention ficou em 6Âº lugar (mecanismo de atenÃ§Ã£o nÃ£o foi efetivo)

#### GRU (Gated Recurrent Unit)
- **Melhor Modelo**: gru_bidirectional (2Âº lugar)
- **CaracterÃ­sticas**: ConsistÃªncia alta entre todas as variaÃ§Ãµes
- **Destaque**: Melhor **equilÃ­brio performance/complexidade**
- **ObservaÃ§Ã£o**: gru_large (3Âº) competiu diretamente com lstm_large (4Âº)

#### MLP (Multi-Layer Perceptron)
- **Modelo Avaliado**: mlp_large (7Âº lugar)
- **CaracterÃ­sticas**: Performance inferior para sÃ©ries temporais
- **LimitaÃ§Ã£o**: Ãšnica arquitetura com EQMN2 > 1.0 (pior que modelo naive)
- **Aplicabilidade**: Inadequado para prediÃ§Ãµes de sÃ©ries temporais complexas

### ğŸ¯ AnÃ¡lise das MÃ©tricas Normalizadas

#### EQMN1 (Normalizado pela VariÃ¢ncia)
- **Excelentes** (< 0.1): Todos os modelos recorrentes
- **Melhor**: lstm_bidirectional (0.009211)
- **InterpretaÃ§Ã£o**: Todos os modelos RNN capturaram bem a variabilidade dos dados

#### EQMN2 (Normalizado pelo Modelo Naive)
- **Superiores ao Naive** (< 1.0): Todos exceto MLP
- **Melhor**: lstm_bidirectional (0.159208)
- **CrÃ­tico**: mlp_large (1.161922) foi **pior que modelo naive**

### ğŸ§  AnÃ¡lise de ResÃ­duos

#### Modelos com ResÃ­duos Ideais
- **lstm_bidirectional**: Sem viÃ©s, simÃ©tricos
- **gru_bidirectional**: Sem viÃ©s, simÃ©tricos
- **gru_attention**: **Ãšnica distribuiÃ§Ã£o normal dos resÃ­duos** (p > 0.05)

#### Modelos com LimitaÃ§Ãµes
- **mlp_large**: PossÃ­vel viÃ©s nos resÃ­duos
- **lstm_large**: Assimetria e curtose excessiva
- **lstm_attention**: Curtose normal, mas nÃ£o normalidade

## ğŸ’¡ RecomendaÃ§Ãµes por CenÃ¡rio de Uso

### ğŸ¯ Para MÃ¡xima PrecisÃ£o
**Recomendado**: **lstm_bidirectional**
- **RÂ² = 0.990789** (melhor)
- **RMSE = 0.036060** (menor erro)
- **MAPE = 4.98%** (erro percentual muito baixo)
- **AplicaÃ§Ã£o**: Sistemas crÃ­ticos, pesquisa cientÃ­fica

### âš–ï¸ Para EquilÃ­brio Performance/EficiÃªncia
**Recomendado**: **gru_bidirectional**
- **RÂ² = 0.984880** (excelente)
- **Menor complexidade** que LSTM equivalente
- **ResÃ­duos bem comportados**
- **AplicaÃ§Ã£o**: Sistemas de produÃ§Ã£o, aplicaÃ§Ãµes comerciais

### ğŸš€ Para Sistemas com RestriÃ§Ãµes Computacionais
**Recomendado**: **gru_large**
- **RÂ² = 0.984210** (excelente)
- **Arquitetura unidirecional** (menor custo computacional)
- **Boa generalizaÃ§Ã£o**
- **AplicaÃ§Ã£o**: Dispositivos embarcados, processamento em tempo real

### âŒ NÃ£o Recomendado
**mlp_large**: Performance inadequada para sÃ©ries temporais
- **EQMN2 > 1.0**: Pior que modelo naive
- **MAPE = 26.59%**: Erro muito alto
- **AplicaÃ§Ã£o**: Apenas para fins didÃ¡ticos/comparaÃ§Ã£o

## ğŸ“Š Insights Importantes

### 1. **Superioridade das Arquiteturas Bidirecionais**
- **lstm_bidirectional** e **gru_bidirectional** ocuparam os **dois primeiros lugares**
- Capacidade de processar informaÃ§Ãµes do passado e futuro Ã© crucial para sÃ©ries temporais

### 2. **Efetividade Limitada do Mecanismo de AtenÃ§Ã£o**
- **lstm_attention** (6Âº) e **gru_attention** (5Âº) tiveram performance inferior Ã s versÃµes bidirecionais
- Para sÃ©ries temporais simples, atenÃ§Ã£o pode introduzir complexidade desnecessÃ¡ria

### 3. **InadequaÃ§Ã£o do MLP para SÃ©ries Temporais**
- **mlp_large** foi o Ãºnico modelo com **EQMN2 > 1.0**
- Confirma importÃ¢ncia da memÃ³ria temporal em redes recorrentes

### 4. **ConsistÃªncia das MÃ©tricas Normalizadas**
- **EQMN1 < 0.02** para todos os modelos RNN (excelente)
- **EQMN2 < 0.35** para todos os modelos RNN (muito superior ao naive)

## ğŸ¯ ConfiguraÃ§Ã£o Experimental

### ParÃ¢metros da SÃ©rie Mackey-Glass
- **Pontos**: 10.000
- **ParÃ¢metros**: Ï„=20, Î²=0.4, Î³=0.2, n=18, xâ‚€=0.8
- **Janela de entrada**: 20 pontos
- **PrediÃ§Ã£o**: 1 passo Ã  frente

### ConfiguraÃ§Ãµes de Treinamento
- **Ã‰pocas mÃ¡ximas**: 150
- **Early stopping**: 15 Ã©pocas de paciÃªncia
- **Learning rate**: 1e-3 com scheduler
- **Otimizador**: Adam
- **RegularizaÃ§Ã£o**: L2 (1e-5) + Dropout

### Dataset
- **DivisÃ£o**: 90% treino, 10% validaÃ§Ã£o
- **Pontos de validaÃ§Ã£o**: 998
- **Batch size**: 8192
- **NormalizaÃ§Ã£o**: Min-Max Scaling

## ğŸ“ Arquivos Gerados

### Estrutura de Resultados
```
results/final_report_1748824486/
â”œâ”€â”€ relatorio_textual_20250601_213446.txt      # RelatÃ³rio detalhado
â”œâ”€â”€ 99_tabela_metricas_20250601_213446.csv     # MÃ©tricas em CSV
â”œâ”€â”€ 01_visao_geral_20250601_213446.png         # ComparaÃ§Ã£o visual
â”œâ”€â”€ 99_tabela_metricas_20250601_213446.png     # Tabela formatada
â”œâ”€â”€ 99_comparacao_metricas_20250601_213446.png # GrÃ¡ficos comparativos
â”œâ”€â”€ [modelo]/                                  # Pasta para cada modelo:
â”‚   â”œâ”€â”€ training_curves.png                    # Curvas de treinamento
â”‚   â”œâ”€â”€ predictions.png                        # PrediÃ§Ãµes vs reais
â”‚   â”œâ”€â”€ [modelo]_qq_plot_[timestamp].png       # AnÃ¡lise Q-Q
â”‚   â”œâ”€â”€ [modelo]_cdf_[timestamp].png           # AnÃ¡lise CDF
â”‚   â”œâ”€â”€ best_model.pth                         # Melhor modelo
â”‚   â””â”€â”€ final_model.pth                        # Modelo final
â””â”€â”€ relatorio.html                             # RelatÃ³rio interativo
```

## ğŸ” PrÃ³ximos Passos

### Para Pesquisa
1. **Investigar arquiteturas hÃ­bridas**: Combinar LSTM/GRU com atenÃ§Ã£o temporal
2. **Testar transformers**: Avaliar arquiteturas baseadas apenas em atenÃ§Ã£o
3. **AnÃ¡lise de interpretabilidade**: Compreender o que os modelos aprenderam

### Para ProduÃ§Ã£o
1. **OtimizaÃ§Ã£o de inferÃªncia**: QuantizaÃ§Ã£o e pruning do lstm_bidirectional
2. **Monitoramento de drift**: Detectar mudanÃ§as na distribuiÃ§Ã£o dos dados
3. **Ensemble methods**: Combinar prediÃ§Ãµes dos melhores modelos

### Para ValidaÃ§Ã£o
1. **Teste em sÃ©ries mais longas**: Avaliar generalizaÃ§Ã£o temporal
2. **Cross-validation temporal**: ValidaÃ§Ã£o com mÃºltiplas janelas temporais
3. **Teste de robustez**: Avaliar com diferentes nÃ­veis de ruÃ­do

## ğŸš€ Como Reproduzir os Resultados

### ConfiguraÃ§Ã£o MÃ­nima
```bash
cd mackey_glass_prediction/experiments
python run_experiment.py --models lstm_bidirectional gru_bidirectional gru_large
```

### ConfiguraÃ§Ã£o Completa
```bash
# Reproduzir todos os resultados
python run_experiment.py --models mlp_large lstm_large lstm_bidirectional lstm_attention gru_large gru_bidirectional gru_attention

# Gerar relatÃ³rio interativo
cd ..
python generate_interactive_report.py
```

## ğŸ“š Links Ãšteis

- **[ğŸ“– README.md](README.md)** - DocumentaÃ§Ã£o tÃ©cnica completa
- **[ğŸš€ COMO_USAR.md](COMO_USAR.md)** - Guia prÃ¡tico de execuÃ§Ã£o  
- **[ğŸ“Š RESUMO_EXECUTIVO.md](RESUMO_EXECUTIVO.md)** - VisÃ£o estratÃ©gica do projeto

---

## ğŸ“ ConclusÃµes Finais

### Principais Descobertas
1. **LSTM Bidirectional Ã© o modelo superior** para prediÃ§Ã£o de Mackey-Glass
2. **Arquiteturas bidirecionais superam unidirecionais** consistentemente
3. **GRU oferece excelente custo-benefÃ­cio** comparado ao LSTM
4. **MLP Ã© inadequado** para sÃ©ries temporais com dependÃªncias longas
5. **Mecanismos de atenÃ§Ã£o** nÃ£o foram efetivos neste contexto especÃ­fico

### ImplicaÃ§Ãµes PrÃ¡ticas
- Para **aplicaÃ§Ãµes crÃ­ticas**: Use lstm_bidirectional
- Para **produÃ§Ã£o geral**: Use gru_bidirectional ou gru_large
- Para **pesquisa**: Explore hÃ­bridos e arquiteturas transformer
- **Evite MLP** para prediÃ§Ã£o de sÃ©ries temporais complexas

### ContribuiÃ§Ãµes do Trabalho
- **ComparaÃ§Ã£o abrangente** de arquiteturas em sÃ©rie temporal caÃ³tica
- **AnÃ¡lise detalhada** com mÃ©tricas normalizadas (EQMN1, EQMN2)
- **Metodologia reproduzÃ­vel** com cÃ³digo bem documentado
- **Insights prÃ¡ticos** para seleÃ§Ã£o de modelos em produÃ§Ã£o

---

**Experimento realizado em**: 01 de Junho de 2025  
**Autor**: Rafael Ratacheski de Sousa Raulino  
**Disciplina**: Redes Neurais Profundas - UFG 2025/1  
**Status**: âœ… **ANÃLISE COMPLETA**